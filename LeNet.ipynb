{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, struct\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _read(image,label):\n",
    "    minist_dir = './data/'\n",
    "    with gzip.open(minist_dir + label) as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        label = np.frombuffer(flbl.read(), dtype=np.int8)\n",
    "    with gzip.open(minist_dir + image, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        image = np.frombuffer(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n",
    "    return image, label\n",
    "\n",
    "def get_data():\n",
    "    train_img, train_label = _read(\n",
    "            'train-images-idx3-ubyte.gz',\n",
    "            'train-labels-idx1-ubyte.gz')\n",
    "    test_img, test_label = _read(\n",
    "            't10k-images-idx3-ubyte.gz', \n",
    "            't10k-labels-idx1-ubyte.gz')\n",
    "    return [train_img, train_label, test_img, test_label]\n",
    "\n",
    "X, y, Xt, yt = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_x, train_y = [ torch.from_numpy(X.reshape(-1, 1, 28, 28)).float(), \n",
    "    torch.from_numpy(y.astype(int)) ]\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(dataset=train_dataset, shuffle=True, \n",
    "                          batch_size=batch_size, num_workers=2, pin_memory=True)\n",
    "\n",
    "test_x, test_y = [ torch.from_numpy(Xt.reshape(-1, 1, 28, 28)).float(),\n",
    "    torch.from_numpy(yt.astype(int)) ]\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=True,\n",
    "                         batch_size=batch_size, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def imshow(img, label):\n",
    "    plt.imshow(img.reshape((28, 28)))\n",
    "    plt.title('label: ' + str(label))\n",
    "\n",
    "imshow(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = LeNet()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device:', device)\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.99))\n",
    "\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        import math\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "net.apply(weight_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 0.181253\n",
      "Train Epoch: 0 [23040/60000 (38%)]\tLoss: 1.261541\n",
      "Train Epoch: 0 [46080/60000 (77%)]\tLoss: 0.172843\n",
      "\n",
      "Test set: Average loss: 0.0589, Accuracy: 9881/10000 (98.00%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.058668\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.033376\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.137616\n",
      "\n",
      "Test set: Average loss: 0.0721, Accuracy: 9859/10000 (98.00%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.061060\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.158294\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 2.105832\n",
      "\n",
      "Test set: Average loss: 0.0561, Accuracy: 9891/10000 (98.00%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 4.312164\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.165908\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 5.161349\n",
      "\n",
      "Test set: Average loss: 0.0611, Accuracy: 9895/10000 (98.00%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.023689\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.193771\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 5.748004\n",
      "\n",
      "Test set: Average loss: 0.0547, Accuracy: 9907/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.136752\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 2.148384\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 3.717017\n",
      "\n",
      "Test set: Average loss: 0.0626, Accuracy: 9883/10000 (98.00%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.103004\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 7.584842\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 2.986469\n",
      "\n",
      "Test set: Average loss: 0.0771, Accuracy: 9875/10000 (98.00%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.462852\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 1.892354\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.024918\n",
      "\n",
      "Test set: Average loss: 0.0672, Accuracy: 9888/10000 (98.00%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.002979\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 5.982934\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.853573\n",
      "\n",
      "Test set: Average loss: 0.0727, Accuracy: 9884/10000 (98.00%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.935343\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.009667\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.735963\n",
      "\n",
      "Test set: Average loss: 0.0802, Accuracy: 9888/10000 (98.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    net.train()\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        output = net(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        if batch_idx % 90 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100.0 * batch_idx / len(train_loader), loss.item()))\n",
    "def test():\n",
    "    net.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            output = net(data)\n",
    "            # sum up batch loss\n",
    "            test_loss += criterion(output, label).data.item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100.0 * correct / len(test_loader.dataset)))\n",
    "\n",
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
